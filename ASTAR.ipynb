{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b7c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import heapq\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce33fa5",
   "metadata": {},
   "source": [
    "# Disaster zone environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77bab0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisasterZoneEnv:\n",
    "    \"\"\"\n",
    "    A 2D grid environment for a drone exploring a disaster zone.\n",
    "\n",
    "    Legend (internally stored as integers):\n",
    "        0 -> Empty cell\n",
    "        1 -> Obstacle\n",
    "        2 -> Survivor\n",
    "        3 -> Recharging Point\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 width=8, \n",
    "                 height=8, \n",
    "                 num_obstacles=5, \n",
    "                 num_survivors=3, \n",
    "                 num_resources=2, \n",
    "                 initial_energy=20, \n",
    "                 dynamic=False, \n",
    "                 predefined_grid=None, \n",
    "                 initial_position=None):\n",
    "        \"\"\"\n",
    "        Initialize the environment. If a predefined grid is provided, use it; otherwise, generate randomly.\n",
    "\n",
    "        :param width: Width of the grid.\n",
    "        :param height: Height of the grid.\n",
    "        :param num_obstacles: Number of obstacles.\n",
    "        :param num_survivors: Number of survivors.\n",
    "        :param num_resources: Number of recharging points.\n",
    "        :param initial_energy: Initial energy of the drone.\n",
    "        :param dynamic: Whether the environment is dynamic.\n",
    "        :param predefined_grid: A predefined grid layout (optional).\n",
    "        :param initial_position: Initial position of the drone (required if using predefined grid).\n",
    "        \"\"\"\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.num_obstacles = num_obstacles\n",
    "        self.num_survivors = num_survivors\n",
    "        self.num_resources = num_resources\n",
    "        self.initial_energy = initial_energy\n",
    "        self.dynamic = dynamic\n",
    "        self.energy = initial_energy\n",
    "        self.dynamic_changes = 0  # Counter for dynamic changes\n",
    "\n",
    "        # Use predefined grid if provided\n",
    "        if predefined_grid is not None:\n",
    "            if initial_position is None:\n",
    "                raise ValueError(\"Initial position must be specified when using a predefined grid.\")\n",
    "            self.reset_with_scenario(predefined_grid, initial_position)\n",
    "        else:\n",
    "            self.reset()\n",
    "\n",
    "    def _get_random_empty_cell(self):\n",
    "        \"\"\"\n",
    "        Finds a random empty cell in the grid (cell == 0).\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            x = random.randint(0, self.height - 1)\n",
    "            y = random.randint(0, self.width - 1)\n",
    "            if self.grid[x, y] == 0:  # Ensure the cell is empty\n",
    "                return x, y\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the environment to a new random configuration.\n",
    "        \"\"\"\n",
    "        self.grid = np.zeros((self.height, self.width), dtype=int)\n",
    "\n",
    "        # Place obstacles\n",
    "        for _ in range(self.num_obstacles):\n",
    "            x, y = self._get_random_empty_cell()\n",
    "            self.grid[x, y] = 1\n",
    "\n",
    "        # Place survivors\n",
    "        for _ in range(self.num_survivors):\n",
    "            x, y = self._get_random_empty_cell()\n",
    "            self.grid[x, y] = 2\n",
    "\n",
    "        # Place resources\n",
    "        for _ in range(self.num_resources):\n",
    "            x, y = self._get_random_empty_cell()\n",
    "            self.grid[x, y] = 3\n",
    "\n",
    "        # Random start for the drone\n",
    "        self.drone_x, self.drone_y = self._get_random_empty_cell()\n",
    "        self.energy = self.initial_energy\n",
    "\n",
    "    def reset_with_scenario(self, scenario, initial_position):\n",
    "        \"\"\"\n",
    "        Loads a predefined grid into the environment and sets the drone's initial position.\n",
    "        \"\"\"\n",
    "        scenario = np.array(scenario, dtype=int)  # Ensure the grid is a NumPy array of integers\n",
    "        self.height, self.width = scenario.shape\n",
    "        self.grid = scenario.copy()  # Copy the predefined grid\n",
    "\n",
    "        # Set the drone's position\n",
    "        self.drone_x, self.drone_y = initial_position\n",
    "        self.energy = self.initial_energy\n",
    "\n",
    "    def apply_dynamic_changes(self, step_count):\n",
    "        \"\"\"\n",
    "        Applies dynamic changes to the environment if self.dynamic is True.\n",
    "\n",
    "        :param step_count: Current step count of the simulation.\n",
    "        \"\"\"\n",
    "        if self.dynamic:\n",
    "            # Example dynamic behavior:\n",
    "            # 1) Add a new obstacle every 5 steps\n",
    "            if step_count % 5 == 0:\n",
    "                x, y = self._get_random_empty_cell()\n",
    "                self.grid[x, y] = 1\n",
    "                self.dynamic_changes += 1\n",
    "\n",
    "            # 2) Move all survivors every 3 steps\n",
    "            if step_count % 3 == 0:\n",
    "                survivor_positions = [(x, y) for x in range(self.height) \n",
    "                                      for y in range(self.width) if self.grid[x, y] == 2]\n",
    "                for (sx, sy) in survivor_positions:\n",
    "                    self.grid[sx, sy] = 0  # Remove old survivor\n",
    "                    new_x, new_y = self._get_random_empty_cell()\n",
    "                    self.grid[new_x, new_y] = 2\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"\n",
    "        Renders the grid for visualization in a text-based manner.\n",
    "        \"\"\"\n",
    "        grid_copy = self.grid.astype(str)\n",
    "        grid_copy[grid_copy == '0'] = '.'\n",
    "        grid_copy[grid_copy == '1'] = '#'\n",
    "        grid_copy[grid_copy == '2'] = 'S'\n",
    "        grid_copy[grid_copy == '3'] = 'R'\n",
    "\n",
    "        # Mark the drone in the visualization\n",
    "        grid_copy[self.drone_x, self.drone_y] = 'D'\n",
    "\n",
    "        for row in grid_copy:\n",
    "            print(\" \".join(row))\n",
    "        print(f\"Energy: {self.energy}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c56d01",
   "metadata": {},
   "source": [
    "# A* Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c509070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class AStarDrone:\n",
    "    def __init__(self, env, initial_position):\n",
    "        self.env = env\n",
    "        self.position = initial_position\n",
    "        self.start_position = initial_position\n",
    "        self.visited = set()\n",
    "        self.path = []\n",
    "        self.energy = env.initial_energy\n",
    "        self.steps_taken = 0\n",
    "        self.survivors_rescued = 0\n",
    "        self.resources_collected = 0\n",
    "        self.energy_used = 0\n",
    "\n",
    "    def move(self):\n",
    "        while True:\n",
    "            # Stop if energy is insufficient for further action\n",
    "            if self.energy <= 0:\n",
    "                print(\"Out of energy! Ending mission.\")\n",
    "                return False\n",
    "\n",
    "            # Find the nearest target (survivor or recharge point)\n",
    "            target = self.find_nearest_target()\n",
    "            if not target:\n",
    "                print(\"No reachable targets left. Ending mission.\")\n",
    "                return False\n",
    "\n",
    "            # Use A* to move towards the target\n",
    "            next_move = self.a_star_search(self.position, target)\n",
    "            if next_move:\n",
    "                action = self.calculate_action(self.position, next_move)\n",
    "                self.position = next_move\n",
    "                self.visited.add(self.position)\n",
    "                self.path.append(self.position)\n",
    "\n",
    "                # Deduct energy for the move\n",
    "                self.energy -= 1\n",
    "                self.energy_used += 1\n",
    "                self.steps_taken += 1\n",
    "\n",
    "                # Apply dynamic changes to the environment\n",
    "                self.env.apply_dynamic_changes(self.steps_taken)\n",
    "\n",
    "                # Check and handle grid value\n",
    "                current_cell = self.env.grid[self.position[0]][self.position[1]]\n",
    "                if current_cell == 2:  # Rescue survivor\n",
    "                    self.survivors_rescued += 1\n",
    "                    self.env.grid[self.position[0]][self.position[1]] = 0\n",
    "                    print(f\"Survivor rescued at {self.position}\")\n",
    "                elif current_cell == 3:  # Collect resource (recharge)\n",
    "                    self.resources_collected += 1\n",
    "                    self.env.grid[self.position[0]][self.position[1]] = 0\n",
    "                    self.energy = min(self.energy + 5, self.env.initial_energy)\n",
    "                    print(f\"Recharged at {self.position}. Current energy: {self.energy}\")\n",
    "            else:\n",
    "                print(\"Unable to proceed further. Ending mission.\")\n",
    "                return False\n",
    "\n",
    "    def find_nearest_target(self):\n",
    "        \"\"\"Find the nearest survivor (2) or recharge point (3).\"\"\"\n",
    "        targets = []\n",
    "        for x in range(self.env.height):\n",
    "            for y in range(self.env.width):\n",
    "                if self.env.grid[x][y] in [2, 3]:\n",
    "                    targets.append((x, y))\n",
    "        \n",
    "        if not targets:\n",
    "            return None  # No targets left\n",
    "\n",
    "        # Find the closest target based on Manhattan distance\n",
    "        return min(targets, key=lambda t: self.heuristic(self.position, t))\n",
    "\n",
    "    def a_star_search(self, start, goal):\n",
    "        \"\"\"Perform A* search to find the best path from start to goal.\"\"\"\n",
    "        open_list = []\n",
    "        heapq.heappush(open_list, (0, start))\n",
    "        came_from = {}\n",
    "        g_score = {start: 0}\n",
    "        f_score = {start: self.heuristic(start, goal)}\n",
    "        visited = set()\n",
    "\n",
    "        while open_list:\n",
    "            _, current = heapq.heappop(open_list)\n",
    "            if current == goal:\n",
    "                return self.reconstruct_path(came_from, current)\n",
    "            \n",
    "            visited.add(current)\n",
    "\n",
    "            for neighbor in self.get_neighbors(current):\n",
    "                if neighbor in visited or self.env.grid[neighbor[0]][neighbor[1]] == 1:\n",
    "                    continue\n",
    "\n",
    "                tentative_g_score = g_score[current] + 1\n",
    "                if neighbor not in g_score or tentative_g_score < g_score[neighbor]:\n",
    "                    came_from[neighbor] = current\n",
    "                    g_score[neighbor] = tentative_g_score\n",
    "                    f_score[neighbor] = tentative_g_score + self.heuristic(neighbor, goal)\n",
    "                    heapq.heappush(open_list, (f_score[neighbor], neighbor))\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def get_neighbors(self, position):\n",
    "        \"\"\"Get valid neighboring cells.\"\"\"\n",
    "        x, y = position\n",
    "        neighbors = []\n",
    "        directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "        for dx, dy in directions:\n",
    "            nx, ny = x + dx, y + dy\n",
    "            if 0 <= nx < self.env.height and 0 <= ny < self.env.width:\n",
    "                if self.env.grid[nx][ny] != 1:\n",
    "                    neighbors.append((nx, ny))\n",
    "        return neighbors\n",
    "\n",
    "    def heuristic(self, position, goal):\n",
    "        \"\"\"Heuristic prioritizing Manhattan distance with survivor proximity.\"\"\"\n",
    "        dist = abs(position[0] - goal[0]) + abs(position[1] - goal[1])\n",
    "        # Favor survivors slightly over recharge points\n",
    "        grid_value = self.env.grid[goal[0]][goal[1]]\n",
    "        return dist - (5 if grid_value == 2 else 0)\n",
    "\n",
    "    def reconstruct_path(self, came_from, current):\n",
    "        \"\"\"Reconstruct the path to the goal.\"\"\"\n",
    "        path = []\n",
    "        while current in came_from:\n",
    "            path.append(current)\n",
    "            current = came_from[current]\n",
    "        path.reverse()\n",
    "        return path[0] if path else None\n",
    "\n",
    "    def calculate_action(self, current, next_position):\n",
    "        \"\"\"Determine the action direction.\"\"\"\n",
    "        dx, dy = next_position[0] - current[0], next_position[1] - current[1]\n",
    "        if dx == -1: return 'UP'\n",
    "        if dx == 1: return 'DOWN'\n",
    "        if dy == -1: return 'LEFT'\n",
    "        if dy == 1: return 'RIGHT'\n",
    "        raise ValueError(\"Invalid move.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5313da1",
   "metadata": {},
   "source": [
    "# Testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8917e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class ScenarioTester:\n",
    "    def __init__(self, agent_class, env_params):\n",
    "        \"\"\"\n",
    "        Initialize the tester with the agent class and environment parameters.\n",
    "\n",
    "        :param agent_class: The agent class to be tested (e.g., AStarDrone).\n",
    "        :param env_params: Dictionary of environment parameters.\n",
    "        \"\"\"\n",
    "        self.agent_class = agent_class\n",
    "        self.env_params = env_params\n",
    "        self.results = []  # Store results for each scenario\n",
    "        \n",
    "    def get_initial_position(self, grid):\n",
    "        \"\"\"\n",
    "        Extract the initial position (marked as the first empty cell, 0, in the grid).\n",
    "        \n",
    "        :param grid: The predefined grid scenario.\n",
    "        :return: A tuple (x, y) of the initial position.\n",
    "        \"\"\"\n",
    "        for x in range(len(grid)):\n",
    "            for y in range(len(grid[0])):\n",
    "                if grid[x][y] == 0:  # Assuming the drone starts at the first empty cell\n",
    "                    return (x, y)\n",
    "        raise ValueError(\"The grid must contain at least one empty cell (0) for the drone's starting position.\")\n",
    "\n",
    "    def run_scenario(self, scenario, scenario_id):\n",
    "        \"\"\"\n",
    "        Run a predefined scenario with the given grid and parameters.\n",
    "\n",
    "        :param scenario: The grid representing the scenario.\n",
    "        :param scenario_id: A unique identifier for the scenario.\n",
    "        \"\"\"\n",
    "        # Get the drone's initial position\n",
    "        initial_position = self.get_initial_position(scenario)\n",
    "\n",
    "        # Create environment\n",
    "        env = DisasterZoneEnv(\n",
    "            predefined_grid=scenario,\n",
    "            initial_energy=self.env_params.get(\"initial_energy\", 20),\n",
    "            dynamic=self.env_params.get(\"dynamic\", False),\n",
    "            initial_position=initial_position  # Pass the initial position here\n",
    "        )\n",
    "\n",
    "        # Initialize the agent (no fixed goal as the drone dynamically adapts)\n",
    "        agent = self.agent_class(env, initial_position)\n",
    "\n",
    "        # Measure execution time\n",
    "        start_time = time.time()\n",
    "\n",
    "        while True:\n",
    "            # Capture time at the start of each loop iteration to measure per-loop performance\n",
    "            loop_start_time = time.time()\n",
    "\n",
    "            # Perform operations (dynamic changes, movement, etc.)\n",
    "            if self.env_params.get(\"dynamic\", False):\n",
    "                self.apply_dynamic_changes(env, agent)\n",
    "\n",
    "            if agent.energy <= 0 or not agent.move():\n",
    "                print(\"Terminating scenario: Out of energy or no valid moves remaining.\")\n",
    "                break\n",
    "\n",
    "            # Optionally, render the environment for visualization\n",
    "            env.render()\n",
    "\n",
    "            # Log the agent's current state\n",
    "            print(f\"Agent at position {agent.position}, Energy: {agent.energy}\")\n",
    "            print(f\"Survivors Rescued: {agent.survivors_rescued}, Resources Collected: {agent.resources_collected}\")\n",
    "\n",
    "            # Measure loop duration\n",
    "            loop_end_time = time.time()\n",
    "            loop_duration = loop_end_time - loop_start_time\n",
    "            print(f\"Loop time: {loop_duration:.6f} seconds\")\n",
    "\n",
    "        # Final computation time\n",
    "        end_time = time.time()\n",
    "        computation_time = end_time - start_time\n",
    "\n",
    "        # Record scenario results\n",
    "        self.results.append({\n",
    "            \"Agent Name\": self.agent_class.__name__,\n",
    "            \"Scenario ID\": scenario_id,\n",
    "            \"Steps Taken\": agent.steps_taken,\n",
    "            \"Survivors Rescued\": agent.survivors_rescued,\n",
    "            \"Resources Collected\": agent.resources_collected,\n",
    "            \"Energy Used\": self.env_params.get(\"initial_energy\", 20) - agent.energy,\n",
    "            \"Computation Time (s)\": computation_time\n",
    "        })\n",
    "\n",
    "        print(f\"Scenario {scenario_id} complete. Results:\")\n",
    "        print(f\"Survivors Rescued: {agent.survivors_rescued}, Resources Collected: {agent.resources_collected}\")\n",
    "        print(f\"Steps Taken: {agent.steps_taken}, Energy Used: {self.env_params.get('initial_energy', 20) - agent.energy}\")\n",
    "        print(f\"Computation Time: {computation_time:.6f} seconds\")\n",
    "\n",
    "    def apply_dynamic_changes(self, env, agent):\n",
    "        \"\"\"\n",
    "        Apply dynamic changes to the environment. This can include changing obstacles,\n",
    "        altering resources, or reducing energy levels during the scenario.\n",
    "\n",
    "        :param env: The environment in which the agent is operating.\n",
    "        :param agent: The agent whose state may be affected by dynamic changes.\n",
    "        \"\"\"\n",
    "        print(\"Applying dynamic changes to the environment...\")\n",
    "\n",
    "        # Example: Randomly change an obstacle in the environment grid\n",
    "        import random\n",
    "        x, y = random.randint(0, len(env.grid)-1), random.randint(0, len(env.grid[0])-1)\n",
    "        env.grid[x][y] = random.choice([1, 2, 3])  # 1, 2, or 3 represent different obstacles\n",
    "\n",
    "        # Example: Random energy reduction\n",
    "        energy_decrease = random.randint(1, 3)\n",
    "        agent.energy -= energy_decrease\n",
    "        print(f\"Energy decreased by {energy_decrease}. Current energy: {agent.energy}\")\n",
    "\n",
    "    def display_results(self):\n",
    "        \"\"\"\n",
    "        Display results for all tested scenarios in a formatted table.\n",
    "        \"\"\"\n",
    "        if not self.results:\n",
    "            print(\"No scenarios have been tested yet.\")\n",
    "            return\n",
    "\n",
    "        # Print results table header\n",
    "        print(\"=\" * 100)\n",
    "        print(f\"{'Agent Name':<15} {'Scenario ID':<15} {'Steps Taken':<15} {'Survivors Rescued':<20} {'Resources Collected':<20} {'Energy Used':<15} {'Computation Time (s)':<20}\")\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "        # Print results row by row\n",
    "        for result in self.results:\n",
    "            print(f\"{result['Agent Name']:<15} {result['Scenario ID']:<15} {result['Steps Taken']:<15} {result['Survivors Rescued']:<20} {result['Resources Collected']:<20} {result['Energy Used']:<15} {result['Computation Time (s)']:<20.6f}\")\n",
    "        print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6699dcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying dynamic changes to the environment...\n",
      "Energy decreased by 1. Current energy: 19\n",
      "Survivor rescued at (0, 3)\n",
      "Recharged at (2, 2). Current energy: 18\n",
      "Recharged at (4, 2). Current energy: 20\n",
      "No reachable targets left. Ending mission.\n",
      "Terminating scenario: Out of energy or no valid moves remaining.\n",
      "Scenario Scenario 1 complete. Results:\n",
      "Survivors Rescued: 1, Resources Collected: 2\n",
      "Steps Taken: 8, Energy Used: 0\n",
      "Computation Time: 0.002693 seconds\n",
      "Applying dynamic changes to the environment...\n",
      "Energy decreased by 2. Current energy: 18\n",
      "Recharged at (2, 0). Current energy: 20\n",
      "Survivor rescued at (3, 0)\n",
      "Unable to proceed further. Ending mission.\n",
      "Terminating scenario: Out of energy or no valid moves remaining.\n",
      "Scenario Scenario 2 complete. Results:\n",
      "Survivors Rescued: 1, Resources Collected: 1\n",
      "Steps Taken: 6, Energy Used: 4\n",
      "Computation Time: 0.001502 seconds\n",
      "====================================================================================================\n",
      "Agent Name      Scenario ID     Steps Taken     Survivors Rescued    Resources Collected  Energy Used     Computation Time (s)\n",
      "====================================================================================================\n",
      "AStarDrone      Scenario 1      8               1                    2                    0               0.002693            \n",
      "AStarDrone      Scenario 2      6               1                    1                    4               0.001502            \n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Agent class (replace with the actual agent class)\n",
    "    agent_class = AStarDrone  # The updated drone class with enhanced A* implementation\n",
    "\n",
    "    # Environment parameters (adjust as needed)\n",
    "    env_params = {\n",
    "        \"initial_energy\": 20,  # Initial energy for the drone\n",
    "        \"dynamic\": True        # Enable dynamic changes in the environment\n",
    "    }\n",
    "\n",
    "    # Define different scenarios (predefined grid configurations)\n",
    "    scenario_1 = [\n",
    "        [0, 0, 0, 0, 1],\n",
    "        [0, 1, 0, 2, 0],\n",
    "        [0, 0, 3, 0, 0],\n",
    "        [1, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 1, 0]\n",
    "    ]\n",
    "\n",
    "    scenario_2 = [\n",
    "        [0, 0, 1, 2],\n",
    "        [0, 1, 0, 0],\n",
    "        [3, 0, 1, 0],\n",
    "        [0, 0, 0, 0]\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Initialize the ScenarioTester with the agent class and environment parameters\n",
    "    tester = ScenarioTester(agent_class, env_params)\n",
    "\n",
    "    # Run each scenario with a unique identifier\n",
    "    tester.run_scenario(scenario_1, \"Scenario 1\")\n",
    "    tester.run_scenario(scenario_2, \"Scenario 2\")\n",
    "\n",
    "    # Display the aggregated results for all scenarios\n",
    "    tester.display_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
